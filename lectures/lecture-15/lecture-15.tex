\documentclass{beamer}\usepackage[]{graphicx}\usepackage[]{color}
%% maxwidth is the original width if it is less than linewidth
%% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\definecolor{fgcolor}{rgb}{1, 0.894, 0.769}
\newcommand{\hlnum}[1]{\textcolor[rgb]{0.824,0.412,0.118}{#1}}%
\newcommand{\hlstr}[1]{\textcolor[rgb]{1,0.894,0.71}{#1}}%
\newcommand{\hlcom}[1]{\textcolor[rgb]{0.824,0.706,0.549}{#1}}%
\newcommand{\hlopt}[1]{\textcolor[rgb]{1,0.894,0.769}{#1}}%
\newcommand{\hlstd}[1]{\textcolor[rgb]{1,0.894,0.769}{#1}}%
\newcommand{\hlkwa}[1]{\textcolor[rgb]{0.941,0.902,0.549}{#1}}%
\newcommand{\hlkwb}[1]{\textcolor[rgb]{0.804,0.776,0.451}{#1}}%
\newcommand{\hlkwc}[1]{\textcolor[rgb]{0.78,0.941,0.545}{#1}}%
\newcommand{\hlkwd}[1]{\textcolor[rgb]{1,0.78,0.769}{#1}}%
\let\hlipl\hlkwb

\usepackage{framed}
\makeatletter
\newenvironment{kframe}{%
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}
\usepackage{../371g-slides}
\title{Model Building 2}
\subtitle{Lecture 15}
\author{STA 371G}
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\begin{document}
  
  

  \frame{\maketitle}

  % Show outline at beginning of each section
  \AtBeginSection[]{ 
    \begin{frame}<beamer>
      \tableofcontents[currentsection]
    \end{frame}
  }

  %%%%%%% Slides start here %%%%%%%

  \begin{darkframes}
    
    %{slide 1}
    \begin{frame}{Let's model the batting averages of baseball players}
      \begin{columns}[onlytextwidth]
        \column{.4\textwidth}
          \includegraphics[width=1.6in]{TyCobb.png}
        
        \column{.6\textwidth}
          \begin{itemize}
            \item All of the data here came from \url{http://seanlahman.com/baseball-archive/statistics/}
            \item Some data cleaning was done, mostly to calculate averages
            \item We are going to explore this dataset with best subsets regression
          \end{itemize}
      \end{columns}
    \end{frame}

    \begin{frame}{The response variable}
      \begin{itemize}
        \item \textbf{AVG}: Batting average
      \end{itemize}
    \end{frame}

    %{slide 3}
    \begin{frame}[fragile]{The potential predictors}
      \fontsize{10}{10}\selectfont
      \begin{itemize}
        \item \textbf{YEAR}:         Year this entry calculated for 
        \item \textbf{LG}:           League, either NL or AL
        \item \textbf{OBP}:          On base percentage
        \item \textbf{SLG}:          Slugging average
        \item \textbf{EXP}:          Years of experience
        \item \textbf{PAYR}:         Plate appearances per year
        \item \textbf{MLAVG}:        Batting average for the leauge for the year
        \item \textbf{MLOBP}:        On base percentage for the leaugue for the year
        \item \textbf{MLSLG}:        Slugging percentage for the leaugue for the year
        \item \textbf{AVGcumLag1}:   Player's cumulative batting average for previous years
        \item \textbf{OBPcumLag1}:   Player's cumulative on base percentage for previous years
        \item \textbf{SLGcumLag1}:   Player's cumulative slugging percentage for previous years
        \item \textbf{G}:            Games played (must have been at least 98)
        \item \textbf{YRINDEX}:      Number of years since 1958
      \end{itemize}

      \lc %{Why predict batting average instead of hits?}
    \end{frame}


    %{slide 4}
    \begin{frame}[fragile]{Build model full and check for multicollinearity}
      \fontsize{9}{9}\selectfont

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.137, 0.137, 0.137}\begin{kframe}
\begin{alltt}
\hlstd{full} \hlkwb{<-} \hlkwd{lm}\hlstd{(AVG} \hlopt{~} \hlstd{OBP} \hlopt{+} \hlstd{SLG} \hlopt{+} \hlstd{EXP} \hlopt{+} \hlstd{PAYR} \hlopt{+} \hlstd{MLAVG}
                  \hlopt{+} \hlstd{MLOBP} \hlopt{+} \hlstd{MLSLG} \hlopt{+} \hlstd{AVGcumLag1} \hlopt{+} \hlstd{OBPcumLag1}
                  \hlopt{+} \hlstd{SLGcumLag1} \hlopt{+} \hlstd{G} \hlopt{+} \hlstd{YRINDEX,} \hlkwc{data}\hlstd{=baseball)}

\hlkwd{vif}\hlstd{(full)}
\end{alltt}
\begin{verbatim}
       OBP        SLG        EXP       PAYR      MLAVG      MLOBP 
      3.71       4.32       1.20       1.37      11.07      12.69 
     MLSLG AVGcumLag1 OBPcumLag1 SLGcumLag1          G    YRINDEX 
      7.39       2.09       3.95       3.82       1.12       2.18 
\end{verbatim}
\end{kframe}
\end{knitrout}
      
      \pause
      \fontsize{10}{10}\selectfont
      Uh oh. Houston, we have a problem!

      \lc %{What is the R2 of model full?}
    \end{frame}


    %{slide #5}
    \begin{frame}[fragile]{Look at the correlations to find the problem}
      Columns 8-19 in the data set are numeric. Let's pull those out and look at the correlation matrix.

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.137, 0.137, 0.137}\begin{kframe}
\begin{alltt}
\hlstd{numeric.predictors} \hlkwb{<-} \hlstd{baseball[,}\hlnum{8}\hlopt{:}\hlnum{19}\hlstd{]}
\hlkwd{cor}\hlstd{(numeric.predictors)}
\end{alltt}
\end{kframe}
\end{knitrout}
      
      \lc %{What is the correlation between OBP and SLG?}
    \end{frame}


    %{slide #6}
    \begin{frame}[fragile]{A correlation plot is easier to read!}
      \fontsize{9}{9}\selectfont 
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.137, 0.137, 0.137}\begin{kframe}
\begin{alltt}
\hlkwd{library}\hlstd{(corrplot)}
\hlkwd{corrplot}\hlstd{(}\hlkwd{cor}\hlstd{(numeric.predictors))}
\end{alltt}
\end{kframe}
\input{/tmp/figures/unnamed-chunk-5-1.tikz}

\end{knitrout}
    \end{frame}

    %{slide 7}
    \begin{frame}[fragile]{Reduce multicollinearity by dropping variables}
      The Major League averages are highly correlated with each other; 
      let's keep just MLAVG and drop MLOBP and MLSLG. (This choice depends on our preference of which
      variable would make the most sense to keep.)

      \fontsize{9}{9}\selectfont
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.137, 0.137, 0.137}\begin{kframe}
\begin{alltt}
\hlstd{full} \hlkwb{<-} \hlkwd{lm}\hlstd{(AVG} \hlopt{~} \hlstd{OBP} \hlopt{+} \hlstd{SLG} \hlopt{+} \hlstd{EXP} \hlopt{+} \hlstd{PAYR} \hlopt{+} \hlstd{MLAVG}
                  \hlopt{+} \hlstd{AVGcumLag1} \hlopt{+} \hlstd{OBPcumLag1}
                  \hlopt{+} \hlstd{SLGcumLag1} \hlopt{+} \hlstd{G} \hlopt{+} \hlstd{YRINDEX,} \hlkwc{data}\hlstd{=baseball)}

\hlkwd{vif}\hlstd{(full)}
\end{alltt}
\begin{verbatim}
       OBP        SLG        EXP       PAYR      MLAVG AVGcumLag1 
      3.62       4.29       1.16       1.37       1.86       2.09 
OBPcumLag1 SLGcumLag1          G    YRINDEX 
      3.92       3.79       1.12       1.85 
\end{verbatim}
\end{kframe}
\end{knitrout}

      {Much better!}
    \end{frame}


    %{slide 8}
    \begin{frame}[fragile]{Use best-subsets regression to get a sense of the best predictors}
      \fontsize{9}{9}\selectfont 

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.137, 0.137, 0.137}\begin{kframe}
\begin{alltt}
\hlstd{bestsubsets} \hlkwb{<-} \hlkwd{regsubsets}\hlstd{(AVG} \hlopt{~} \hlstd{OBP} \hlopt{+} \hlstd{SLG} \hlopt{+} \hlstd{EXP} \hlopt{+} \hlstd{PAYR} \hlopt{+} \hlstd{MLAVG}
  \hlopt{+} \hlstd{AVGcumLag1} \hlopt{+} \hlstd{OBPcumLag1} \hlopt{+} \hlstd{SLGcumLag1} \hlopt{+} \hlstd{G} \hlopt{+} \hlstd{YRINDEX,} \hlkwc{data}\hlstd{=baseball)}
\hlkwd{plot}\hlstd{(bestsubsets,} \hlkwc{scale}\hlstd{=}\hlstr{"adjr2"}\hlstd{)}
\end{alltt}
\end{kframe}
\end{knitrout}

      \vspace{-1in}

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.137, 0.137, 0.137}
\input{/tmp/figures/unnamed-chunk-9-1.tikz}

\end{knitrout}
    \end{frame}


    %{slide 9}
    \begin{frame}[fragile]{Use best-subsets regression to get a sense of the best predictors}
      \fontsize{9}{9}\selectfont
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.137, 0.137, 0.137}\begin{kframe}
\begin{alltt}
\hlkwd{plot}\hlstd{(bestsubsets,} \hlkwc{scale}\hlstd{=}\hlstr{"bic"}\hlstd{)}
\end{alltt}
\end{kframe}
\end{knitrout}

      \vspace{-1in}

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.137, 0.137, 0.137}
\input{/tmp/figures/unnamed-chunk-11-1.tikz}

\end{knitrout}
      \lc %{What are the best predictors}
    \end{frame}     


    %{slide 11}
    \begin{frame}[fragile]{Generate the best candidate model}
      \fontsize{8}{8}\selectfont 
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.137, 0.137, 0.137}\begin{kframe}
\begin{verbatim}

Call:
lm(formula = AVG ~ OBP + SLG + AVGcumLag1 + OBPcumLag1 + SLGcumLag1, 
    data = baseball)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.05601 -0.00772  0.00026  0.00818  0.04051 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  0.02787    0.00250    11.2   <2e-16 ***
OBP          0.49821    0.00909    54.8   <2e-16 ***
SLG          0.16083    0.00470    34.2   <2e-16 ***
AVGcumLag1   0.88035    0.01195    73.7   <2e-16 ***
OBPcumLag1  -0.47626    0.01211   -39.3   <2e-16 ***
SLGcumLag1  -0.17183    0.00555   -31.0   <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.0121 on 4529 degrees of freedom
Multiple R-squared:  0.821,	Adjusted R-squared:  0.821 
F-statistic: 4.15e+03 on 5 and 4529 DF,  p-value: <2e-16
\end{verbatim}
\end{kframe}
\end{knitrout}
    \end{frame}

    %{slide 13}
    \begin{frame}[fragile]{Does the National League's Designated Hitter Rule Matter?}
      Let's first look at only the cases where LG is either NL or AL, to simplify the analysis (other rows correspond to a player that switched teams during the season). Then we'll add LG to the model.

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.137, 0.137, 0.137}\begin{kframe}
\begin{alltt}
\hlstd{base1} \hlkwb{<-} \hlstd{baseball[baseball}\hlopt{$}\hlstd{LG} \hlopt{==} \hlstr{"NL"} \hlopt{|}
                  \hlstd{baseball}\hlopt{$}\hlstd{LG} \hlopt{==} \hlstr{"AL"}\hlstd{,]}
\hlstd{modelLG} \hlkwb{<-} \hlkwd{lm}\hlstd{(AVG} \hlopt{~} \hlstd{OBP} \hlopt{+} \hlstd{SLG} \hlopt{+} \hlstd{AVGcumLag1} \hlopt{+} \hlstd{OBPcumLag1}
                      \hlopt{+} \hlstd{SLGcumLag1} \hlopt{+} \hlstd{LG,} \hlkwc{data}\hlstd{=base1)}
\end{alltt}
\end{kframe}
\end{knitrout}
    \end{frame}

    \begin{frame}[fragile]
      \fontsize{8}{8}\selectfont
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.137, 0.137, 0.137}\begin{kframe}
\begin{alltt}
\hlkwd{summary}\hlstd{(modelLG)}
\end{alltt}
\begin{verbatim}

Call:
lm(formula = AVG ~ OBP + SLG + AVGcumLag1 + OBPcumLag1 + SLGcumLag1 + 
    LG, data = base1)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.05583 -0.00782  0.00026  0.00822  0.04022 

Coefficients:
             Estimate Std. Error t value Pr(>|t|)    
(Intercept)  0.028177   0.002559   11.01   <2e-16 ***
OBP          0.499326   0.009356   53.37   <2e-16 ***
SLG          0.159058   0.004830   32.93   <2e-16 ***
AVGcumLag1   0.877759   0.012311   71.30   <2e-16 ***
OBPcumLag1  -0.476465   0.012464  -38.23   <2e-16 ***
SLGcumLag1  -0.170083   0.005708  -29.80   <2e-16 ***
LGNL         0.000303   0.000372    0.81     0.42    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.0122 on 4306 degrees of freedom
Multiple R-squared:  0.821,	Adjusted R-squared:  0.821 
F-statistic: 3.29e+03 on 6 and 4306 DF,  p-value: <2e-16
\end{verbatim}
\end{kframe}
\end{knitrout}
      \lc %{What is the p-value of league?}
      \lc %{Does the designated hitter rule predict}
    \end{frame}

    %{slide 15}
    \begin{frame}[fragile]{Is this model really useful?}
      \begin{itemize}[<+->]
        \item Automated regression model selection methods cannot make something out of nothing. 
        \item If you omit some important variables or fail to use data transformations when they are needed, or if the assumption of linear or linearizable relationships is simply wrong, the model is a bad one, no matter what the $R^2$.  
        \item Use your own judgment and intuition about your data to try to fine-tune whatever the computer comes up with.
      \end{itemize} 
    \end{frame}

    \begin{frame}[fragile]{Surprise!}
      This data is all random numbers! Here's how it was generated:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.137, 0.137, 0.137}\begin{kframe}
\begin{alltt}
\hlstd{y} \hlkwb{<-} \hlkwd{rnorm}\hlstd{(}\hlnum{100}\hlstd{)}
\hlstd{x1} \hlkwb{<-} \hlkwd{rnorm}\hlstd{(}\hlnum{100}\hlstd{)}
\hlstd{x2} \hlkwb{<-} \hlkwd{rnorm}\hlstd{(}\hlnum{100}\hlstd{)}
\hlcom{# etc}
\end{alltt}
\end{kframe}
\end{knitrout}

      $R^2=0.21$, so 21\% of the variance in $Y$ is explained by random numbers!  
      \lc %{What did I do wrong?}
    \end{frame}

    \begin{frame}[fragile]{Be careful of spurious correlations and overfitting!}
      \begin{itemize}
        \item If you have more than 1 predictor for 10-15 cases, you are likely to see spurious correlations.
        \item If you fit models with meaningless variables, you are fitting noise and will end up with an \alert{overfit} model that is not predictive on new data. 
      \end{itemize} 
    \end{frame}

    \begin{frame}
      \fullpagepicture{spurious-correlation}
    \end{frame}
  \end{darkframes}
\end{document}
