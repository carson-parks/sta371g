\documentclass{beamer}
\usepackage{../371g-slides}
\title{Model Building}
\subtitle{Lecture 14}
\author{STA 371G}

\begin{document}
  <<setup, include=F, cache=F>>=
  opts_knit$set(global.par=T)
  knit_hooks$set(crop=hook_pdfcrop)
  opts_chunk$set(dev='tikz', external=F, fig.path='c:/tmp/figures/', comment=NA, fig.width=4, fig.height=3, crop=T, sanitize=T, tidy=F)
  knit_theme$set('camo')
  @
  <<include=F, cache=F>>=
  library(car)
  library(stats)
  library(leaps)
  counties <- read.csv("../../data/counties.csv", na.strings="")
  par(fg='#fefefe', col.axis='#fefefe', col.lab='#fefefe', col.main="#fefefe", mar=c(5.1, 4.1, 1.1, 2.1))
  @

  \frame{\maketitle}

  % Show outline at beginning of each section
  \AtBeginSection[]{ 
    \begin{frame}<beamer>
      \tableofcontents[currentsection]
    \end{frame}
  }

  %%%%%%% Slides start here %%%%%%%

  \begin{darkframes}
    
    
    \begin{frame}{There is a Primary Care Physician Shortage in Texas!}
      \fontsize{10}{10}\selectfont
      \begin{center}
        \includegraphics[width=3.8in]{DocShortage} \\
      \end{center} \pause

      \begin{center}
        {What might explain this? There are many potential predictors!}
      \end{center} 

      \begin{columns}[onlytextwidth]
        \column{.5\textwidth} 
          \begin{itemize}
            \item Small counties
            \item Poverty
            \item Health insurance
          \end{itemize}
        \column{.5\textwidth}
          \begin{itemize}
            \item Unemployment
            \item Large rural areas
            \item Something else?
          \end{itemize}
      \end{columns}
      
      \lc %{smallest population}
    \end{frame}

    \begin{frame}[fragile]{What to do if there a lot of potential predictors}
      \begin{itemize}[<+->]
        \item Previously, we assumed that the explanatory variables were either from a small set or chosen in advance.
        \item However, figuring out what variables to use to predict the number of physicians that a county has, is a critical portion of the analysis in this case.
        \item This type of analysis is an exploratory study.
      \end{itemize} 
    \end{frame}

    \begin{frame}[fragile]{An exploratory study of the Texas physician shortage}
      \begin{itemize}[<+->]
        \item Exploratory studies are observational studies, in that the variables are observed rather than controlled.
        \item Multicollinearity is much more likely in an exploratory study than in an experiment or a confirmatory study.
        \item Exploratory studies require the most in terms of model selection. Automated tools are helpful, but judgement is still needed!
      \end{itemize} 
    \end{frame}

    \begin{frame}[fragile]{Population as a predictor of number of physicians}
      \fontsize{8}{8}\selectfont    
      <<>>=
      plot(counties$Population, counties$Physicians)
      popmodel <- lm(counties$Physicians ~ counties$Population)
      abline(popmodel)
      @

      \lc %{What is R2 if we predict physicians from population?}
    \end{frame}

    \begin{frame}[fragile]{Transform and Subset the data}
      \fontsize{8}{8}\selectfont
        <<>>=

        # Transform Physians
        counties$PhysiciansPer10000 <- 
                      (counties$Physicians/counties$Population)*10000

        # Remove the very small and very large counties
        mcounties <- counties[counties$Population < 500000 & 
                              counties$Population > 10000,]

        # Show medium counties with no physicians
        mcounties[mcounties$Physicians == 0, c(1,5,12)]
        @

        \lc %{Why would we want to remove large counties}
    \end{frame}

    \begin{frame}[fragile]{The 10 potential x variables}
    \fontsize{10}{10}\selectfont
          \begin{itemize}
            \item LandArea:       Area in square miles
            \item PctRural:       Percentage rural land
            \item MedianIncome:   Median household income
            \item Population:     Population
            \item PctUnder18:     Percent children
            \item PctOver65:      Percent seniors
            \item PctPoverty:     Percent below the poverty line
            \item PctUninsured:   Percent without health insurance
            \item PctSomeCollege: Percent with some higher education
            \item PctUnemployed:  Percent unemployed
          \end{itemize}
    \end{frame}

    \begin{frame}[fragile]{Building all of the possible models}
      \begin{itemize}[<+->]
        \item Previously, we built the full model and eliminated the variables in order of largest p-value (or smallest t-score). 
        \item This is what the reading assignment calls backward stepwise regression.
        \item This method is good, but it is not guaranteed to find to the best model!
        \item If there are n candidate predictor variables, there are $2^n$ possible models, and we need to look at ALL of them to be sure that we have found the best model.
        \item This is where R's automated model building tools help.
      \end{itemize} 

      \lc  %{If there are 5 candidate predictor variables}
    \end{frame}


    \begin{frame}[fragile]{How do you decide which model is best?}
      \begin{itemize}[<+->]
        \item All model measuring criteria try to find a balance between the predictive power of the model and the number of variables.
        \item No method is ideal in all situations, so it is generally best to use multiple methods and compare the results.
       \end{itemize} 

    \end{frame}  


    \begin{frame}[fragile]{What are the criteria for comparing models?}
      \begin{itemize}[<+->]
        \item We have used $R^2$ and Adjusted-$R^2$ before.
        \item $R^2$ is not good for comparing models with different numbers of variables because it tends to increase a little with each additional variable just due to randomness.
        \item Adjusted-$R^2$ is better because it multiplies $R^2$ by a penalty that depends on the number of variables. However, the penalty is somewhat arbitrary.
        \item AIC (Akaikeâ€™s Information Criterion) and the very similar BIC (your reading calls it SBC) are other widely used criteria.
        \item There more, but we won't go into them.
 
      \end{itemize} 
    \end{frame}


    \begin{frame}[fragile]{Stepping forwards}
       The step() function uses the AIC criterion to compare models. You must build the null and the full models first.

      \fontsize{8}{8}\selectfont

      <<>>=

      null <- lm(PhysiciansPer10000~1, data=mcounties)

      full <- lm(PhysiciansPer10000 ~ LandArea + PctRural + MedianIncome
                                    + Population + PctUnder18 + PctOver65
                                    + PctPoverty + PctUninsured 
                                    + PctSomeCollege + PctUnemployed, 
                                    data=mcounties)

      stepforwardOut <- step(null, scope=list(lower=null, upper=full), 
                                   direction ="forward")

      @

      \lc %{Examine stepforwardOut. Which variable is the most significant}
    \end{frame}

  
    \begin{frame}[fragile]{Check the LINE assumptions}
      model stepforwardOut's residuals look ok
      \fontsize{8}{8}\selectfont
      <<echo=F>>=
      par(mfrow=c(2,2)) # change the panel layout to 2x2
      @
      <<fig.width=4.5>>=
      plot(stepforwardOut)
      @
      <<echo=F>>=
      par(mfrow=c(1,1)) # change the panel layout back
      @
    \end{frame}


    \begin{frame}[fragile]{Examine stepforwardOut}
    \fontsize{8}{8}\selectfont
     <<>>=
     # check the summary
     #summary(stepforwardOut)

     # Check stepForwardOut for multicollinearity
     vif(stepforwardOut)

     @

     \lc %{Examine stepbforwardOut}
    \end{frame}


    \begin{frame}[fragile]{Stepping backwards and both ways}
     This model looks pretty good, but is it the best?
     You can also step backward or on both directions.

    \fontsize{8}{8}\selectfont

      <<>>=

      stepbackwardOut <- step(null, scope=list(lower=null, upper=full), 
                              direction ="backward")

      stepbothOut <- step(null, scope=list(lower=null, upper=full), 
                          direction ="both")

      @

      \lc %{Take a look at stepbackwardOut}
    \end{frame}


    \begin{frame}[fragile]{Best Subsets Regression}
     
     Step only uses AIC criterion for comparing models. regsubsets is more flexible about criteria and calculates all possible subsets. 

    \fontsize{8}{8}\selectfont
     <<>>=
     
     library(leaps)

     regsubsets.out <- regsubsets(PhysiciansPer10000 ~ LandArea + PctRural 
                                  + MedianIncome + Population + PctUnder18 
                                  + PctOver65 + PctPoverty + PctUninsured
                                  + PctSomeCollege + PctUnemployed, data=mcounties)

     @

    \end{frame}


    \begin{frame}[fragile]{Best Subsets Regression}
    \fontsize{8}{8}\selectfont
     Step only uses AIC criterion for comparing models. regsubsets is more flexible about criteria and calculates all possible subsets. 
      
     <<>>=
     # Set the plot window up so you can examine the output side by side
     layout(matrix(1:2, ncol=2))
     #plot(regsubsets.out, scale="adjr2")  # use adjusted R^2
     #plot(regsubsets.out, scale="bic")    # use SBC

     # Don't forget to reset the plot window!
     layout(matrix(1:1, ncol=1))
     @

    \end{frame}

    \begin{frame}{Look at this interesting plot}
    \fontsize{8}{8}\selectfont
      \begin{center}
        \includegraphics[width=3.8in]{bestsubsets} \\
      \end{center} 

      \begin{center}
        {Black indicates that a variable is included in the model, while white indicates that it is not.}
      \end{center} 
      
    \end{frame}


    \begin{frame}[fragile]{Putting things together}
      \begin{itemize}[<+->]
        \item Look at multiple statistics. They generally say similar things.
        \item Find the middle ground between an underspecified model and extraneous variables.
        \item Fine tune the model to get a correctly specified model; you may need to transform predictors and/or add interactions.
        \item Think about logical reasons why certain predictors might be useful, don't just focus on p-values.
      \end{itemize} 
    \end{frame}


    \begin{frame}[fragile]{Be careful of getting too crazy}
      \begin{itemize}[<+->]
        \item A general guideline is that you should not even consider more than one variable for every 10 to 15 cases in your dataset. 
        \item Otherwise, you can select the ones that happen to fit the data the best and essentially create a spurious correlation!
        \item Rember to check for multicolliearity and the LINE assumptions!
      \end{itemize} 
    \end{frame}


  \end{darkframes}
\end{document}